%        File: covo.tex
%     Created: Di Okt 16 10:00  2018 C
% Last Change: Di Okt 16 10:00  2018 C
%

\documentclass[a4paper]{report}
% ***************************PACKAGES***************************
\usepackage{graphicx}
\usepackage{caption,setspace}
\usepackage{subcaption}
\captionsetup[figure]{width=0.7\textwidth,font={small}}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{siunitx}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{mwe}
\usepackage{tabularx}
\usepackage{cite}
\usepackage{hyperref}
\usepackage{bookmark}


% ***************************CONFIGS***************************
% for numbering per section
\numberwithin{figure}{section}
% removing ugly colored rectangles from references
\usepackage{xcolor}
\hypersetup{
    hidelinks,
    colorlinks = false,
    %linkcolor={black},
    %citecolor={black},
    %urlcolor={black}
  }
% command for table tabular alignment
\newcolumntype{L}{>{\raggedright\arraybackslash}X}
% command for argmin and argmax
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\R}{\mathbb{R}}
% commands for cascading subfigures
\newsavebox{\subfloatbox}
\newcommand{\topfloat}[2][\empty]% #1 = caption, #2=image
 {\savebox\subfloatbox{#2}%
  \begin{minipage}[t]{\wd\subfloatbox}
    \usebox\subfloatbox
    \subcaption{#1}
  \end{minipage}}
\newcommand{\bottomfloat}[2][\empty]% #1 = caption, #2=image
 {\savebox\subfloatbox{#2}%
  \begin{minipage}[b]{\wd\subfloatbox}
    \captionsetup{position=top}%
    \subcaption{#1}
    \usebox\subfloatbox
  \end{minipage}}



% ***************************ACRONYMS***************************
\usepackage[toc, shortcuts]{glossaries}
\makeglossaries
\newacronym{vo}{VO}{Visual Odometry}



\begin{document}

% ***************************TITLE***************************
\begin{titlepage}
\begin{center}

%  \includegraphics[width=\textwidth]{../fig/tuc_logo.jpg}

\vspace{1.5cm}


{\Huge \textbf{Master Thesis}}\\
\vspace{0.5cm}
{\huge \textbf{An Error Aware RGB-D \\Visual Odometry}}


\vspace{2.5cm}

{\huge \textbf{U\u{g}ur Bolat}}

\vfill

Date:

\vspace{1.2cm}

Supervisors: \\
Dr.-Ing. Sven Lange \\
M.Sc. Tim Pfeifer

\vspace{0.8cm}

Faculty of Electrical Engineering and Information Technology\\
Professorship of Process Automation

\end{center}
\end{titlepage}

% ***************************TABLE OF CONTENT ETC.***************************
\tableofcontents
\newpage
\listoffigures
\listoftables
\newpage
\printglossary[type=\acronymtype,title={Abbreviations}]
\newpage

% ***************************DOCUMENT***************************

\begin{abstract}


\end{abstract}

\newpage

% ***************************CP1-INTRO***************************
\chapter{Introduction} \label{cp_intro}


\newpage

% ***************************CP2-VO***************************
\chapter{Visual Odometry} \label{cp_vo}

\section{Related Works} \label{sc_related_works}

\section{Camera Models} \label{sc_cam_models}

A camera maps from a 3D world scene to a 2D image plane. We call this process 
projection operation. Since the \acrshort{vo} systems process camera image 
sequences, one has to model this projection operation accurately. One of the 
basic camera modeling technique is the \textit{Pinhole Model} where the projection of 
the 3D points are mapped on a 2D image plane (also called focal plane). 

\subsection{The Pinhole Model} \label{sbsc_pinhole}

In this model, the camera centre sits behind the image plane.
The Z-axis, 
also called \textit{principal axis}, of this 
coordinate system points out through the origin of the image plane and the 
point where pierce through image plane is called the \textit{pricipal point}. 
We can also see how other two axes are located in Figure-\ref{fig:pinhole} 
and this is known as the \textit{Camera Coordinate System} $(x_{cam}, y_{cam}, z_{cam})$.


\begin{figure}[H]
	\centering
	\includegraphics[width=\linewidth,natwidth=640,natheight=640]
  {fig/ref_imgs/pinhole_model.png}
  \caption{REMEMBER TO DRAW HORIZ/VERT Fx and Fy. The Pinhole Model}
	\label{fig:pinhole}
\end{figure}

Thanks to geometrical propotion property, we can project 
the 3D point $(X, Y, Z)^T$ in Euclidean space $\mathbb{R}^3$
to the 2D point $(U,V)^T = (f_xX/Z, f_yY/Z)^T$ in Euclidean space $\mathbb{R}^2$, 
where $f_x$ and $f_y$ are the \textit{focal lengths} 
between the camera centre and the pricipal 
point with respect to horizontal and vertical axis of the Camera Coordinate 
System respectively.
After projection, we obtain a 2D 
point that we represent on the 
\textit{Image Coordinate Frame} $(u_{img},v_{img})$.

To be more specific,
we can write the projection operation as a linear mapping function 
in the following way if we utilize the homogenous coordinates:

\begin{equation}
  \begin{pmatrix}
    U\\
    V\\
    1
  \end{pmatrix}
  \sim
  Z
  \begin{pmatrix}
    f_xX/Z\\
    f_yY/Z\\
    1
  \end{pmatrix}
  =
  \begin{pmatrix}
    f_xX\\
    f_yY\\
    Z
  \end{pmatrix}
  =
  \begin{bmatrix}
    f_x & 0 & 0 & 0\\
    0 & f_y & 0 & 0\\
    0 & 0 & 1 & 0\\
  \end{bmatrix}
  \begin{pmatrix}
    X\\
    Y\\
    Z\\
    1
  \end{pmatrix}
\end{equation} \label{eq:proj_func_w_f}

This equation applies for the case when 3D points are 
projected onto a plane where the principal point is the origin. 
However, the common convention in partice 
is to have the origin at the (not entirely sure) left-bottom corner not in the centre.

\begin{figure}[H]
	\centering
	\includegraphics[width=\linewidth,natwidth=640,natheight=640]
  {fig/ref_imgs/pinhole_offset.png}
	\caption{Principle Point Offset}
	\label{fig:pinhole_offset}
\end{figure}

Thus, we get offsets, which can further be added into our function:

\begin{equation}
  \begin{pmatrix}
    U\\
    V\\
    1
  \end{pmatrix}
  \sim
  Z
  \begin{pmatrix}
    (f_xX + Z c_x)/Z\\
    (f_yY + Z c_y)/Z\\
    1
  \end{pmatrix}
  =
  \begin{pmatrix}
    f_xX + Z c_x\\
    f_yY + Z c_y\\
    Z
  \end{pmatrix}
  =
  \begin{bmatrix}
    f_x & 0 & c_x & 0\\
    0 & f_y & c_y & 0\\
    0 & 0 & 1 & 0\\
  \end{bmatrix}
  \begin{pmatrix}
    X\\
    Y\\
    Z\\
    1
  \end{pmatrix}
\end{equation} \label{eq:proj_func_w_f_c}

where $c_x$ and $c_y$ are coordinates of the principal point \textbf{p}.

In addition to pricipal offsets, inaccurately synchronized pixel-sampling 
process can result in \textit{skewed pixels}. This camera imperfection leads to 
non-square pixels as seen in Figure-\ref{fig:skewed}.

\begin{figure}[H]
	\centering
  \includegraphics[width=0.5\linewidth,natwidth=640,natheight=640]
  {fig/ref_imgs/skew.png}
  \caption{REMEMBER TO DRAW FOR X and Y.Skew and Non-Square Pixels}
	\label{fig:skewed}
\end{figure}

We can scale the square pixels, having 1:1 pixel aspect ratio, with the 
corresponding skew parameters $\eta_x$, $\eta_y$ and $s$:

\begin{equation}
  \begin{pmatrix}
    U\\
    V\\
    1
  \end{pmatrix}
  \sim
  \begin{bmatrix}
    f_x\eta_x & s & c_x & 0\\
    0 & f_y\eta_y & c_y & 0\\
    0 & 0 & 1 & 0\\
  \end{bmatrix}
  \begin{pmatrix}
    X\\
    Y\\
    Z\\
    1
  \end{pmatrix}
  =
  \begin{bmatrix}
    \alpha_x & s & c_x & 0\\
    0 & \alpha_y & c_y & 0\\
    0 & 0 & 1 & 0\\
  \end{bmatrix}
  \begin{pmatrix}
    X\\
    Y\\
    Z\\
    1
  \end{pmatrix}
\end{equation} \label{eq:proj_func_w_square_pix_skew}

Generally, the skewed pixels issues occurred in ealier versions of CCD cameras 
and this is mostly fixed in new generation digital cameras. Therefore, 
we can neglate this effect by taking $\eta_x=1$, $\eta_y=1$ and $s=0$.

Next, we can extract:

\begin{equation}
  \mathbf{K} = 
  \begin{bmatrix}
    \alpha_x & s & c_x\\
    0 & \alpha_y & c_y\\
    0 & 0 & 1\\
  \end{bmatrix}
\end{equation} \label{eq:k_matrix}

The $\mathbf{K}$ matrix is called 
\textit{intrinsic parameters matrix}, which represents the characteristics of 
a camera sensor. Note that, we 
can further reformulate the notation \ref{eq:proj_func_w_square_pix_skew} in more 
compact form:

\begin{equation}
  \mathbf{U_{img}} = \mathbf{K}[\mathbf{I}|\mathbf{0}]\mathbf{X_{cam}}
\end{equation} \label{eq:simplyfied_proj_func}

\begin{figure}[H]
	\centering
  \includegraphics[width=\linewidth,natwidth=640,natheight=640]
  {fig/ref_imgs/cam_model_rot_trans.png}
  \caption{Camera Rotation and Translation}
  \label{fig:cam_model_rot_trans}
\end{figure}

Remember that, the Z-axis of the Camera Coordinate System aligns with the 
principal axis that is \textit{local} to camera frame. In fact, we have 3D points that 
we represent in the \textit{World Coordinate System} 
which we refer as the \textit{global} frame. 
These two coordinates systems 
can be transformed one another by a rotation and a translation as it is 
depicted in Figure-\ref{fig:cam_model_rot_trans} but we are interested in 
converting from the World Coordinate to Camera Coordinate System in this case.
To do so, we first perform series of rotations around each axis of the 
cartesian coordinate system in Euclidean space by using 
\textit{rotation matrices} where $R_x, R_y, R_z \in SO(3)$ is the rotation group:

\begin{equation}
  R_x(\theta) = 
  \begin{bmatrix}
    1 & 0 & 0\\
    0 & cos\theta & -sin\theta\\
    0 & sin\theta & cos\theta
  \end{bmatrix}
\end{equation} \label{eq:rot_matrx_x}

\begin{equation}
  R_y(\theta) = 
  \begin{bmatrix}
    cos\theta & 0 & -sin\theta\\
    0 & 1 & 0\\
    sin\theta & 0 & cos\theta
  \end{bmatrix}
\end{equation} \label{eq:rot_matrx_y}

\begin{equation}
  R_z(\theta) = 
  \begin{bmatrix}
    cos\theta & -sin\theta & 0\\
    sin\theta & cos\theta & 0\\
    0 & 0 & 1
  \end{bmatrix}
\end{equation} \label{eq:rot_matrx_z}

One can concatenate all three rotations about axes z, y, x respectively:

\begin{equation}
  \mathbf{R} = \mathbf{R_z(\gamma)}\mathbf{R_y(\beta)}\mathbf{R_x(\alpha)}
  =
  \begin{bmatrix}
    r_{11} & r_{12} & r_{13}\\
    r_{21} & r_{22} & r_{23}\\
    r_{31} & r_{32} & r_{33}\\
  \end{bmatrix}
\end{equation} \label{eq:rot_matrix_derivation}

Then, perform a translation $\mathbf{t} \in \R^{3x1}$:

\begin{equation}
  \mathbf{t} = 
  \begin{bmatrix}
    t_x \\ t_y \\ t_z
  \end{bmatrix}
\end{equation} \label{eq:translation}

We can also compound the rotation matrix and the translation vector into 
one matrix:

\begin{equation}
  \mathbf{T} =
  \begin{bmatrix}
    r_{11} & r_{12} & r_{13} & t_x\\
    r_{21} & r_{22} & r_{23} & t_y\\
    r_{31} & r_{32} & r_{33} & t_z\\
  \end{bmatrix}
\end{equation} \label{eq:transformation_matrix}

The $\mathbf{T} \in \R^{4x3}$ matrix in fact represents 
a \textit{rigid-body transformation}, which we call 
\textit{extrinsic camera parameters}.

Finally, we combine intrinsic $\mathbf{K}$ and 
extrinsic $\mathbf{T}$ matrices to form the following notation: 

\begin{equation}
  \mathbf{U_{img}} = 
  \mathbf{H}\mathbf{X_{world}} = 
  \mathbf{K}\mathbf{T}\mathbf{X_{world}} = 
  \mathbf{K}[\mathbf{R}|\mathbf{t}]\mathbf{X_{world}}
\end{equation} \label{eq:simplyfied_proj_func}

\begin{equation}
  \mathbf{U_{img}} = \mathbf{F_{proj}}(\mathbf{X_{world}})
\end{equation} \label{eq:simplyfied_proj_func}

where $\mathbf{F_{proj}}(\mathbf{X_{world}})$ is the \textit{projection function}, which takes 
the 3D points in the World Coordinate System, transforms to 
the Camera Coordinate Systems and then maps them into the Image 
Coordinate Systems.

To build any reliable computer vision application with digital cameras, it is 
to important to find a good $\mathbf{H}$ \textit{projection matrix} 
(alternatively refered as \textit{Homography matrix} in camera calibration)
The next section describes one of many numerical methods for estimationg this 
matrix in literature.

\subsection{Camera Calibration} \label{sb_sc_calibration}

Lens Distortion

\begin{figure}[H]
	\centering
  \includegraphics[width=0.3\linewidth,natwidth=640,natheight=640]
  {fig/ref_imgs/cam_distortion.png}
  \caption{Camera Distortion}
  \label{fig:cam_distortion}
\end{figure}

\begin{equation}
\begin{split}
  x' = X/Z\\
  y' = Y/Z
\end{split}
\end{equation}

\begin{equation}
\begin{split}
  x'' = x'(1+ k_1 r^2 + k_2 r^4) + 2 p_1 x' y' + p_2 (r^2+2x'^2)\\
  y'' = y'(1+ k_1 r^2 + k_2 r^4) + p_1 (r^2+2y'^2) + 2p_2 x'y'\\
\end{split}
\end{equation}

\begin{equation}
  \begin{pmatrix}
    U\\
    V\\
    1
  \end{pmatrix}
  =
  \begin{pmatrix}
    f_x x'' + c_x\\
    f_y x'' + c_y\\
    1
  \end{pmatrix}
  \sim
  Z
  \begin{pmatrix}
    (f_xX + Z c_x)/Z\\
    (f_yY + Z c_y)/Z\\
    1
  \end{pmatrix}
    =
    \mathbf{K} [\mathbf{R}|\mathbf{t}]
  \begin{pmatrix}
    X\\
    Y\\
    Z\\
    1
  \end{pmatrix}
\end{equation} \label{eq:proj_func_w_f_c}


Calibrating with Checkerboard

\begin{figure}[H]
	\centering
  \includegraphics[width=\linewidth,natwidth=640,natheight=640]
  {fig/ref_imgs/checkerboard.png}
  \caption{Checkerboard}
  \label{fig:checkerboard}
\end{figure}

\begin{equation}
  \argmin_{\mathbf{K}, k, \mathbf{R}_i, \mathbf{t}_i}
\end{equation}

\section{Image Features} \label{sc_img_features}

\section{Feature Matching} \label{sc_feature_matching}

\section{Motion Estimation} \label{sc_motion_estim}

% ***************************CP3-MOTIVATION***************************
\chapter{Motivation} \label{cp_motivation}

% ***************************CP4-CoVO***************************
\chapter{An Error-Aware RGB-D Visual Odometry} \label{cp_covo}

REMEMBER TO DRAW X,Y COORD. WRT CAM. COORD WITH RIGHT HAND FOR KINECT!

\section{Modeling Spatial Uncertainty} \label{sc_spatial_uncertainty}

\subsection{Kinect Calibration} \label{sb_sc_kinect_calibration}

\section{Weighted Least-Squares Optimization} \label{sc_weighted_lsq}

\section{Covariance Estimation} \label{sc_covariance_estim}

% ***************************CP5-EVALUATION***************************
\chapter{Evaluation} \label{cp_evaluation}

% ***************************CP6-CONCLUSION***************************
\chapter{Conclusion} \label{cp_conc}

% ***************************CP7-EVALUATION***************************
\chapter{Reference} \label{cp_ref}


% ***************************CP7-EVALUATION***************************
\chapter{Appendices} \label{cp_appendices}

\end{document}


